{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8044a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted image saved as cipher_output.png\n",
      "Secret h vector (first 5 dims): [0.00852050632238388, -0.05593032389879227, 0.34271544218063354, 0.1163710206747055, -0.023216672241687775]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esl01\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# --- Encoder: Text → Latent h ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, latent_dim=512, n_layers=4, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.to_latent = nn.Linear(embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids: [seq_len]\n",
    "        x = self.embed(input_ids).unsqueeze(1)      # [seq,1,embed]\n",
    "        x = self.transformer(x).squeeze(1)          # [seq,embed]\n",
    "        h_feat = x.mean(dim=0)                      # [embed]\n",
    "        h = self.to_latent(h_feat)                  # [latent]\n",
    "        return h\n",
    "\n",
    "# --- Stylizer: Latent h → Abstract PNG Image ---\n",
    "class Stylizer(nn.Module):\n",
    "    def __init__(self, latent_dim=512, img_size=64):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 3 * img_size * img_size)\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def forward(self, h):\n",
    "        img_flat = self.fc(h)                       # [3*H*W]\n",
    "        img = img_flat.view(3, self.img_size, self.img_size)\n",
    "        return torch.sigmoid(img)\n",
    "\n",
    "# --- Tokenizer Stub ---\n",
    "def simple_tokenize(text, vocab_size=10000):\n",
    "    return torch.tensor([ord(c) % vocab_size for c in text], dtype=torch.long)\n",
    "\n",
    "# --- End-to-End Example ---\n",
    "if __name__ == '__main__':\n",
    "    text = \"HELLO CUBIST CIPHER\"\n",
    "    input_ids = simple_tokenize(text)\n",
    "\n",
    "    # Instantiate modules\n",
    "    encoder = Encoder(vocab_size=10000)\n",
    "    stylizer = Stylizer(latent_dim=512, img_size=64)\n",
    "\n",
    "    # Forward pass: Text → h → Image\n",
    "    h = encoder(input_ids)\n",
    "    img = stylizer(h)                           # Tensor shape: [3,64,64]\n",
    "\n",
    "    # Save image\n",
    "    save_image(img, 'cipher_output.png')\n",
    "    print(f\"Encrypted image saved as cipher_output.png\")\n",
    "\n",
    "    # h is the secret byproduct\n",
    "    print(f\"Secret h vector (first 5 dims): {h[:5].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e8585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔒 암호문 이미지: cipher_output.png 생성 완료\n",
      "🔓 복호 결과 (근사): fV6VVVVmVVVVVVmmVi\u0016\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# --- Decoder: Latent h → Recovered Text ---\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=512, embed_dim=256, vocab_size=10000, n_layers=4, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, embed_dim)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.transformer = nn.TransformerDecoder(decoder_layer, num_layers=n_layers)\n",
    "        self.to_logits = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, h, seq_len):\n",
    "        # h: [latent_dim], seq_len: 원하는 복원 길이\n",
    "        # 1) Latent → 임시 메모리 Representation\n",
    "        memory = self.fc(h).unsqueeze(0).unsqueeze(1)  # [1,1,embed_dim]\n",
    "        # 2) 빈 타깃 시퀀스 생성\n",
    "        tgt = torch.zeros(seq_len, 1, memory.size(-1))\n",
    "        # 3) Transformer Decoder 통과\n",
    "        out = self.transformer(tgt, memory).squeeze(1)  # [seq_len, embed_dim]\n",
    "        # 4) 어휘 토큰 로짓으로 변환\n",
    "        logits = self.to_logits(out)                     # [seq_len, vocab_size]\n",
    "        return logits\n",
    "\n",
    "# --- 통합 예제 (Encoder→Stylizer→Decoder) ---\n",
    "if __name__ == '__main__':\n",
    "    from torchvision.utils import save_image\n",
    "\n",
    "    # 1) Text → Token IDs\n",
    "    text = \"HELLO CUBIST CIPHER\"\n",
    "    input_ids = simple_tokenize(text)\n",
    "\n",
    "    # 2) 모듈 인스턴스화\n",
    "    encoder = Encoder(vocab_size=10000)\n",
    "    stylizer = Stylizer(latent_dim=512, img_size=64)\n",
    "    decoder = Decoder(latent_dim=512, embed_dim=256, vocab_size=10000)\n",
    "\n",
    "    # 3) 암호화: Text → h → Image\n",
    "    h = encoder(input_ids)\n",
    "    img = stylizer(h)\n",
    "    save_image(img, 'cipher_output.png')\n",
    "    print(\"🔒 암호문 이미지: cipher_output.png 생성 완료\")\n",
    "\n",
    "    # 4) 복호화: h + 모델 → Text\n",
    "    logits = decoder(h, seq_len=len(input_ids))\n",
    "    pred_ids = logits.argmax(dim=-1)\n",
    "    recovered = ''.join(chr(int(pid) % 128) for pid in pred_ids)\n",
    "    print(\"🔓 복호 결과 (근사):\", recovered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "675b53d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config] vocab_size=128, latent_dim=512, seq_len=16, batch_size=32, epochs=20, sigma=1.5\n",
      "[Data] Loaded 600 examples, 19 batches per epoch\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.026095137000083923, 0.28160974383354187, 0.18624871969223022, -0.4062309265136719, 0.1963960975408554]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep1 Batch0/19, Loss=4.7012\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7426954507827759, -0.14725257456302643, 0.22180543839931488, -0.99001145362854, -0.5345509648323059]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6401399374008179, -0.3297048807144165, 0.17414914071559906, -0.7524224519729614, -0.9419687986373901]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.48660632967948914, -0.4504845142364502, 0.023089256137609482, -0.8009634017944336, -1.0775309801101685]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4928502142429352, -0.5422667264938354, -0.012223154306411743, -0.7260380387306213, -1.1357706785202026]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.39703625440597534, -0.49465760588645935, -0.07873719185590744, -0.7750450372695923, -1.2220474481582642]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.33307647705078125, -0.5769703388214111, -0.0798356831073761, -0.7332075238227844, -1.3757984638214111]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2768966555595398, -0.5965566635131836, -0.16958358883857727, -0.7542209029197693, -1.4756741523742676]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.33513957262039185, -0.4783093333244324, -0.20720018446445465, -0.7911550998687744, -1.4889365434646606]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2989194989204407, -0.4554191529750824, -0.182222381234169, -0.7967305779457092, -1.5452450513839722]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3594617247581482, -0.3943265378475189, -0.19470523297786713, -0.7206629514694214, -1.5565608739852905]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep1 Batch10/19, Loss=2.8122\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3927841782569885, -0.45783641934394836, -0.24228765070438385, -0.7451186180114746, -1.617551326751709]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34160202741622925, -0.42848318815231323, -0.3524330258369446, -0.7464697957038879, -1.5171266794204712]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3436746895313263, -0.3956698477268219, -0.2548556327819824, -0.6970395445823669, -1.6062545776367188]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2650589048862457, -0.423033744096756, -0.3182859718799591, -0.7200639247894287, -1.6234633922576904]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34947293996810913, -0.40864357352256775, -0.28091418743133545, -0.6834751963615417, -1.6518194675445557]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3114435076713562, -0.4069629907608032, -0.2728349268436432, -0.7370103597640991, -1.6449675559997559]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.22669856250286102, -0.3607189357280731, -0.31527870893478394, -0.7192878723144531, -1.7046140432357788]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.326896071434021, -0.4139839708805084, -0.31002891063690186, -0.799696147441864, -1.682878851890564]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 1 Average Loss: 2.9796\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2756003141403198, -0.4772980809211731, -0.37584561109542847, -0.7274681329727173, -1.6840523481369019]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep2 Batch0/19, Loss=2.7480\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3213876187801361, -0.3846452236175537, -0.32476523518562317, -0.7411638498306274, -1.6974433660507202]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3547547459602356, -0.3567906320095062, -0.39686042070388794, -0.7132160663604736, -1.6982903480529785]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.30253005027770996, -0.40140295028686523, -0.336038738489151, -0.7772725224494934, -1.7547279596328735]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.32559487223625183, -0.448265016078949, -0.3421923518180847, -0.7684156894683838, -1.680095911026001]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34426644444465637, -0.3638937473297119, -0.31871145963668823, -0.6957163214683533, -1.6995038986206055]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34901368618011475, -0.3826175630092621, -0.45124906301498413, -0.7073475122451782, -1.707970142364502]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34755927324295044, -0.3354102075099945, -0.34718057513237, -0.6673246622085571, -1.7206567525863647]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3285274803638458, -0.32314732670783997, -0.323312371969223, -0.6944938898086548, -1.730271816253662]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34879201650619507, -0.3017198145389557, -0.37563279271125793, -0.7404534816741943, -1.7214878797531128]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3342519700527191, -0.2615806758403778, -0.3476807773113251, -0.6587299704551697, -1.7161026000976562]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep2 Batch10/19, Loss=2.7051\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.34971514344215393, -0.33839917182922363, -0.4212286174297333, -0.7082696557044983, -1.6846827268600464]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.310743123292923, -0.3262004852294922, -0.3415050208568573, -0.7372010946273804, -1.6532695293426514]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2592618465423584, -0.30316415429115295, -0.409719318151474, -0.7387987971305847, -1.7361342906951904]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.33777910470962524, -0.3464037775993347, -0.38449859619140625, -0.6877346634864807, -1.6968469619750977]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.28447943925857544, -0.3285377025604248, -0.44118958711624146, -0.7159559726715088, -1.7144290208816528]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.37225592136383057, -0.2827058434486389, -0.3851413428783417, -0.6937432885169983, -1.687368392944336]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.28864625096321106, -0.3499511480331421, -0.3799871802330017, -0.759796142578125, -1.7222305536270142]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.3802511692047119, -0.2685397267341614, -0.31804293394088745, -0.6486167907714844, -1.6302131414413452]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 2 Average Loss: 2.7273\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.305595725774765, -0.3848685324192047, -0.2461828887462616, -0.6358785629272461, -1.6761152744293213]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep3 Batch0/19, Loss=2.7233\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.33644744753837585, -0.3064986765384674, -0.35986047983169556, -0.6393938660621643, -1.667782187461853]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3012619614601135, -0.3477708399295807, -0.35873159766197205, -0.6234955787658691, -1.7183582782745361]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.27206915616989136, -0.262397825717926, -0.4621485769748688, -0.6627991795539856, -1.7131320238113403]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.365963339805603, -0.22407224774360657, -0.41495802998542786, -0.615403413772583, -1.6633954048156738]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.28997501730918884, -0.3217603266239166, -0.48078349232673645, -0.6253511309623718, -1.680129051208496]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2694038450717926, -0.3008117377758026, -0.37717774510383606, -0.5421555042266846, -1.7326030731201172]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3407302498817444, -0.28344282507896423, -0.4576992690563202, -0.5573474168777466, -1.6315968036651611]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3447571396827698, -0.3461410701274872, -0.37776505947113037, -0.5403406023979187, -1.624464511871338]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.17058804631233215, -0.3327834904193878, -0.3766673803329468, -0.6004341840744019, -1.6763098239898682]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.27540478110313416, -0.32174330949783325, -0.4248654842376709, -0.613333523273468, -1.6421747207641602]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep3 Batch10/19, Loss=2.6722\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.30850839614868164, -0.3920036554336548, -0.41994500160217285, -0.5946075916290283, -1.5906827449798584]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2412692904472351, -0.32917162775993347, -0.4126172661781311, -0.524835467338562, -1.6730237007141113]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.21401332318782806, -0.39821669459342957, -0.375752717256546, -0.5185759663581848, -1.7231677770614624]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.23363465070724487, -0.3979393541812897, -0.3766050934791565, -0.48933976888656616, -1.7109419107437134]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.17616550624370575, -0.3839225172996521, -0.37076881527900696, -0.5374926924705505, -1.628528356552124]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.21745485067367554, -0.32801270484924316, -0.46518775820732117, -0.48235777020454407, -1.6649750471115112]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.18717016279697418, -0.5028526186943054, -0.41143471002578735, -0.6358883380889893, -1.544260025024414]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.2236531674861908, -0.4777940809726715, -0.39090582728385925, -0.6335824728012085, -1.5665924549102783]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 3 Average Loss: 2.7094\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.20627626776695251, -0.40460526943206787, -0.4317329227924347, -0.5353638529777527, -1.5760899782180786]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep4 Batch0/19, Loss=2.7116\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.21955466270446777, -0.3280494213104248, -0.3585997521877289, -0.4828226566314697, -1.5659021139144897]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.11723121255636215, -0.46777307987213135, -0.49450212717056274, -0.5760621428489685, -1.5642704963684082]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2806687653064728, -0.34719350934028625, -0.3463958501815796, -0.3322179317474365, -1.6210041046142578]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.1409168541431427, -0.3408437669277191, -0.46978169679641724, -0.504574179649353, -1.49295973777771]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.27341359853744507, -0.3148268461227417, -0.3638658821582794, -0.1919538378715515, -1.6427183151245117]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.27264803647994995, -0.27635642886161804, -0.31242647767066956, -0.0647786557674408, -1.6197317838668823]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2384423315525055, -0.14474117755889893, -0.3745558261871338, 0.032670218497514725, -1.6135295629501343]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.2657955288887024, -0.12112686038017273, -0.27318623661994934, 0.23521962761878967, -1.5778546333312988]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.25330114364624023, -0.49773696064949036, -0.6311987042427063, -0.697841227054596, -1.1018158197402954]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.33839499950408936, 0.01673378422856331, -0.10990196466445923, 0.6193636655807495, -1.4570369720458984]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep4 Batch10/19, Loss=2.6001\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.5301633477210999, -0.5088741183280945, -0.8270747065544128, -0.7669619917869568, -0.7682114243507385]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.36157941818237305, 0.12953819334506989, -0.13367904722690582, 1.1319669485092163, -1.2541927099227905]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.37582847476005554, 0.12935538589954376, -0.1426805853843689, 1.1567002534866333, -1.2748533487319946]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3997867703437805, 0.15923945605754852, -0.1438402384519577, 1.1995227336883545, -1.2290899753570557]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4100412428379059, 0.1577988713979721, -0.10607390850782394, 1.2772750854492188, -1.1973708868026733]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5117560625076294, 0.20905858278274536, -0.17617973685264587, 1.356374740600586, -1.143446922302246]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.1056734323501587, -0.5058476328849792, -0.5809720158576965, -0.4315703511238098, 0.27628979086875916]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-1.2279679775238037, -0.5067698955535889, -0.4722554683685303, -0.5572945475578308, 0.20370712876319885]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 4 Average Loss: 2.6177\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5244643688201904, 0.10375040769577026, -0.19737619161605835, 1.2654211521148682, -1.2756599187850952]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep5 Batch0/19, Loss=2.4513\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.1686537265777588, -0.5184478163719177, -0.3850909471511841, -0.6760236620903015, 0.2501218616962433]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5793793201446533, 0.10527490079402924, -0.1838645339012146, 1.326460361480713, -1.323386311531067]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0689743757247925, -0.3913553059101105, -0.3755006790161133, -0.7766178846359253, 0.26197949051856995]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6795601844787598, 0.07058151066303253, -0.19219188392162323, 1.1420485973358154, -1.3291544914245605]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7710996866226196, 0.08954459428787231, -0.1118767037987709, 1.1263412237167358, -1.3700690269470215]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7694957852363586, 0.0192059725522995, -0.18008582293987274, 1.0835679769515991, -1.484706997871399]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8540451526641846, 0.07384026795625687, -0.12609021365642548, 1.0364506244659424, -1.5039745569229126]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7429050803184509, 0.012064063921570778, -0.1740717887878418, 1.061142086982727, -1.5795588493347168]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8850607872009277, -0.005617497488856316, -0.16993103921413422, 0.9754239320755005, -1.635862946510315]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.1113072633743286, -0.46761345863342285, -0.21810121834278107, -0.8451804518699646, 0.2441316843032837]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep5 Batch10/19, Loss=2.4616\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8633554577827454, -0.09094158560037613, -0.17646542191505432, 0.8126030564308167, -1.66219162940979]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.069628119468689, -0.4807436466217041, -0.17520755529403687, -0.9459973573684692, 0.21317335963249207]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0779712200164795, -0.498524934053421, -0.14282649755477905, -0.8418297171592712, 0.20108649134635925]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8111231327056885, -0.10400112718343735, -0.2566535472869873, 0.6657194495201111, -1.8105082511901855]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0741488933563232, -0.46943598985671997, -0.18413189053535461, -0.90172278881073, 0.2741714119911194]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6998226046562195, -0.23026476800441742, -0.19103141129016876, 0.4768892526626587, -1.7940303087234497]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8076810240745544, -0.26949432492256165, -0.2343755066394806, 0.4538865089416504, -1.804499864578247]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-1.1139887571334839, -0.4330984950065613, -0.040943779051303864, -0.9324248433113098, 0.24070453643798828]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 5 Average Loss: 2.4578\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0968605279922485, -0.4424871504306793, -0.07806447148323059, -0.919619083404541, 0.2229117453098297]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep6 Batch0/19, Loss=2.4628\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.051703691482544, -0.4801984131336212, -0.11503924429416656, -0.9441032409667969, 0.2910284399986267]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7404177784919739, -0.20839698612689972, -0.22300347685813904, 0.2595178186893463, -1.8910703659057617]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7231586575508118, -0.28354519605636597, -0.20059426128864288, 0.17916038632392883, -1.8650652170181274]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6881011128425598, -0.28060322999954224, -0.25325340032577515, 0.14343515038490295, -1.9044451713562012]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0822359323501587, -0.4679275453090668, -0.12366887927055359, -0.865951657295227, 0.18674159049987793]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6953520178794861, -0.2872224450111389, -0.26893505454063416, 0.17613592743873596, -1.8920392990112305]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0644614696502686, -0.5274319052696228, -0.13672256469726562, -0.8960163593292236, 0.18755820393562317]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6874775886535645, -0.2974945902824402, -0.2803710401058197, 0.19079305231571198, -1.9184411764144897]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5964744091033936, -0.31093406677246094, -0.22115789353847504, 0.12346968054771423, -1.8834002017974854]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5941223502159119, -0.27881309390068054, -0.19396139681339264, 0.05658763647079468, -1.975341558456421]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep6 Batch10/19, Loss=2.4954\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8842081427574158, -0.19356600940227509, -0.043937258422374725, 0.4045196771621704, -1.9262415170669556]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.0375864505767822, -0.4532003104686737, -0.09218587726354599, -0.9719371199607849, 0.07374841719865799]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.2175343036651611, 0.054753661155700684, 0.002606539987027645, 0.8251803517341614, -1.7387499809265137]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.9071649312973022, -0.49132612347602844, -0.05034502595663071, -0.9423173666000366, 0.05437367409467697]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3187363147735596, 0.19747275114059448, 0.06632562726736069, 1.0088977813720703, -1.5210522413253784]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.7709516882896423, -0.5155394673347473, -0.0631532296538353, -0.8922472596168518, -0.20071743428707123]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.8154127597808838, -0.3761156499385834, -0.00846206583082676, -0.859616219997406, -0.2920374572277069]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[1.3073781728744507, 0.2938072383403778, 0.17906895279884338, 1.160583734512329, -1.5110706090927124]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 6 Average Loss: 2.4539\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.714844822883606, -0.3752390146255493, -0.045929163694381714, -0.8847364187240601, -0.41190439462661743]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep7 Batch0/19, Loss=2.4407\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3486624956130981, 0.2786117494106293, 0.2101602405309677, 1.1580933332443237, -1.4236254692077637]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.2796777486801147, 0.31105804443359375, 0.22571030259132385, 1.1451654434204102, -1.3086283206939697]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.5293703675270081, -0.35655519366264343, 0.0901167169213295, -0.7267891764640808, -0.5748884677886963]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.296471357345581, 0.35347628593444824, 0.2142162173986435, 1.2588939666748047, -1.316825270652771]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.5221402645111084, -0.3666689395904541, 0.11442427337169647, -0.7169322967529297, -0.6199738383293152]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.5023890733718872, -0.3256404995918274, 0.03835936263203621, -0.6923597455024719, -0.7383784651756287]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3980445861816406, 0.3668951690196991, 0.25513118505477905, 1.2850306034088135, -1.2902323007583618]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3587507009506226, 0.39919978380203247, 0.2856064736843109, 1.1999138593673706, -1.3167321681976318]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.311010479927063, 0.2847166359424591, 0.3637107312679291, 1.3201649188995361, -1.290881633758545]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3937996625900269, 0.3702225685119629, 0.2927818298339844, 1.3020695447921753, -1.2729912996292114]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep7 Batch10/19, Loss=2.4248\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3785440921783447, 0.4501515030860901, 0.31180402636528015, 1.3382803201675415, -1.332310438156128]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.308070182800293, 0.3487432301044464, 0.32569393515586853, 1.3348392248153687, -1.4037611484527588]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.2199271321296692, -0.22548271715641022, 0.22484424710273743, -0.502828061580658, -0.9970237612724304]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3482304811477661, 0.3581927418708801, 0.2810065448284149, 1.4232425689697266, -1.3366503715515137]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-0.1813909411430359, -0.35726243257522583, 0.12622058391571045, -0.5058824419975281, -1.0409170389175415]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.408643126487732, 0.41554781794548035, 0.2866167426109314, 1.278789758682251, -1.1814959049224854]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3130080699920654, 0.3650300204753876, 0.3077947199344635, 1.2945282459259033, -1.3077375888824463]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-0.8059213161468506, -0.34533435106277466, 0.018569806590676308, -0.8263781666755676, -0.28417712450027466]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 7 Average Loss: 2.4504\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.1948750019073486, -0.2239089459180832, -0.26544100046157837, -1.0635757446289062, 0.34481823444366455]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep8 Batch0/19, Loss=2.4501\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.4655497074127197, 0.38422441482543945, 0.4209475815296173, 1.2048708200454712, -1.408278226852417]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.5255600214004517, 0.3106326758861542, 0.4188854992389679, 1.2040215730667114, -1.3348731994628906]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.4302176237106323, 0.3369766175746918, 0.4737175703048706, 1.3387527465820312, -1.4507583379745483]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.472664475440979, 0.31543365120887756, 0.3570742905139923, 1.2626652717590332, -1.4445371627807617]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.4749295711517334, 0.2299000471830368, 0.42696380615234375, 1.2702863216400146, -1.6076710224151611]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.8113818168640137, -0.15603910386562347, -0.46156319975852966, -1.1556079387664795, 1.213023066520691]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.8043662309646606, -0.2094322293996811, -0.5418810844421387, -1.1832189559936523, 1.2449921369552612]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.3855066299438477, 0.36248284578323364, 0.4081697165966034, 1.2295928001403809, -1.4391322135925293]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.366665244102478, 0.32797494530677795, 0.35030725598335266, 1.2369389533996582, -1.6009105443954468]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.340034008026123, 0.3447359800338745, 0.3970048129558563, 1.1912211179733276, -1.526336908340454]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep8 Batch10/19, Loss=2.4713\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.2860842943191528, 0.2779652178287506, 0.4210435152053833, 1.2040609121322632, -1.5139473676681519]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.322952389717102, 0.2821480333805084, 0.4203333258628845, 1.103823184967041, -1.5773605108261108]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.2727677822113037, 0.36927756667137146, 0.42379119992256165, 1.1851736307144165, -1.467833161354065]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.1859525442123413, 0.36683225631713867, 0.41950827836990356, 1.128811240196228, -1.4531575441360474]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.253618836402893, 0.37351521849632263, 0.3623638153076172, 1.1622350215911865, -1.4994112253189087]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9523392915725708, 0.001696795574389398, -0.6328386068344116, -1.1672837734222412, 1.4765217304229736]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.8103396892547607, -0.11146382987499237, -0.5761042833328247, -1.1709016561508179, 1.4176098108291626]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-1.9571372270584106, -0.13159945607185364, -0.6757627129554749, -1.3108278512954712, 1.4965726137161255]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 8 Average Loss: 2.4460\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.971923589706421, -0.11044211685657501, -0.529636561870575, -1.1786057949066162, 1.536160945892334]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep9 Batch0/19, Loss=2.4476\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9975370168685913, -0.03208225965499878, -0.6167144775390625, -1.193586826324463, 1.5875332355499268]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.1337493658065796, 0.40237197279930115, 0.3688068389892578, 1.0126018524169922, -1.450403094291687]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.054046869277954, 0.469835489988327, 0.34785932302474976, 1.0192034244537354, -1.4413292407989502]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.04125714302063, 0.02977980673313141, -0.6592700481414795, -1.1456120014190674, 1.4813205003738403]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.0565439462661743, 0.3301774859428406, 0.2909069061279297, 1.0303218364715576, -1.427809715270996]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.1015374660491943, 0.4463220238685608, 0.28344669938087463, 0.9992838501930237, -1.360259771347046]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.1181844472885132, 0.3672507405281067, 0.30860772728919983, 0.9700444936752319, -1.3430010080337524]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.8826438188552856, 0.008184489794075489, -0.5822214484214783, -1.1417614221572876, 1.5546835660934448]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.0357922315597534, 0.3300488591194153, 0.28940120339393616, 1.0108835697174072, -1.3943899869918823]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9065521955490112, -0.0702892392873764, -0.6675651669502258, -1.1276475191116333, 1.5241367816925049]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep9 Batch10/19, Loss=2.4072\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9913344383239746, 0.007820416241884232, -0.7038232088088989, -1.1944048404693604, 1.5530582666397095]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9805444478988647, -0.026914183050394058, -0.6298498511314392, -1.2280372381210327, 1.5314610004425049]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.000028133392334, -0.038458313792943954, -0.7388378381729126, -1.0994784832000732, 1.528016209602356]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9168657064437866, -0.01210060715675354, -0.7448850274085999, -1.0933537483215332, 1.528379201889038]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9843332767486572, 0.3465052843093872, 0.33236584067344666, 1.0846962928771973, -1.4133442640304565]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0250296592712402, -0.031037604436278343, -0.7015636563301086, -1.191779375076294, 1.5307586193084717]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9125757813453674, 0.37064328789711, 0.27096647024154663, 0.9589007496833801, -1.3249820470809937]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-2.006303310394287, 0.035340242087841034, -0.6241506934165955, -1.166961431503296, 1.6003974676132202]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 9 Average Loss: 2.4448\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0266268253326416, -0.005453796591609716, -0.6667007207870483, -1.131455421447754, 1.6446958780288696]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep10 Batch0/19, Loss=2.4508\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9539974927902222, 0.036628399044275284, -0.7280722856521606, -1.1626118421554565, 1.5747792720794678]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.963233470916748, 0.06773409247398376, -0.6217726469039917, -1.1802618503570557, 1.5622913837432861]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9028328657150269, 0.3679440915584564, 0.2709340453147888, 0.9063670635223389, -1.3647822141647339]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[1.012263536453247, 0.4061189591884613, 0.2665185332298279, 0.9340226054191589, -1.3057001829147339]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8872640132904053, 0.43058377504348755, 0.3230105936527252, 0.952152669429779, -1.408451795578003]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0630593299865723, -0.005101402755826712, -0.6937047839164734, -1.197424054145813, 1.4634158611297607]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9718958139419556, -0.017623543739318848, -0.5939286947250366, -1.2628974914550781, 1.518593668937683]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8869445323944092, 0.43146106600761414, 0.30618831515312195, 0.9114875793457031, -1.3249808549880981]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0078117847442627, -0.03291343152523041, -0.5415028929710388, -1.1655199527740479, 1.5426511764526367]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9222241044044495, 0.3680727779865265, 0.3496447205543518, 0.8861928582191467, -1.3412127494812012]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep10 Batch10/19, Loss=2.4287\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9303707480430603, 0.3483086824417114, 0.3226168751716614, 0.9090113043785095, -1.3306556940078735]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.826134979724884, 0.4179172217845917, 0.2943577766418457, 0.8255590200424194, -1.273114800453186]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8369963765144348, 0.406023234128952, 0.20089055597782135, 0.8779232501983643, -1.3887825012207031]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9691190719604492, 0.45179325342178345, 0.24486888945102692, 0.8901205062866211, -1.3713480234146118]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.89304119348526, 0.3126322031021118, 0.2872088551521301, 0.882801353931427, -1.3492538928985596]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9304968118667603, 0.386674165725708, 0.3209935426712036, 0.9058381915092468, -1.3501687049865723]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0110230445861816, -0.044191330671310425, -0.6153554916381836, -1.105082392692566, 1.524216890335083]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-2.003467321395874, -0.06383967399597168, -0.6404446959495544, -1.033722996711731, 1.622330904006958]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 10 Average Loss: 2.4452\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8907412886619568, 0.42376065254211426, 0.3022361695766449, 0.875924825668335, -1.2248002290725708]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep11 Batch0/19, Loss=2.4569\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0614097118377686, 0.06600422412157059, -0.6954501271247864, -1.128567099571228, 1.6155061721801758]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0252885818481445, 0.07286173850297928, -0.6775272488594055, -1.163655400276184, 1.556545615196228]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8884690999984741, 0.41270914673805237, 0.3317049443721771, 0.9159635305404663, -1.3439421653747559]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.020819664001465, -0.03598978742957115, -0.6662694811820984, -1.129409909248352, 1.5723180770874023]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9498113393783569, 0.46637555956840515, 0.29987025260925293, 0.859760582447052, -1.3021880388259888]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.154995918273926, -0.028943534940481186, -0.6982308626174927, -1.135695457458496, 1.519526720046997]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9865660667419434, 0.4884773790836334, 0.2880973517894745, 0.7837969064712524, -1.3352781534194946]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8886356949806213, 0.3867555260658264, 0.3540809154510498, 0.8458660244941711, -1.2737997770309448]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.012904644012451, -0.07202836126089096, -0.6160693764686584, -1.109616756439209, 1.5013980865478516]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9912711381912231, 0.4278019070625305, 0.317975252866745, 0.8443652987480164, -1.2800213098526]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep11 Batch10/19, Loss=2.4570\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8392135500907898, 0.3494214713573456, 0.33535853028297424, 0.7537428140640259, -1.2806127071380615]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8151185512542725, 0.387625128030777, 0.2987798750400543, 0.8715915679931641, -1.2872915267944336]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9196521043777466, 0.4892406463623047, 0.31248417496681213, 0.7453010678291321, -1.2442564964294434]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8682733178138733, 0.4130934178829193, 0.3003968894481659, 0.8432159423828125, -1.314747929573059]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8587052822113037, 0.41643160581588745, 0.21847638487815857, 0.8451099991798401, -1.337021827697754]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0729100704193115, 0.0038789575919508934, -0.7864749431610107, -1.1364703178405762, 1.507670283317566]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.006957769393921, 0.06089179217815399, -0.7211109399795532, -1.1328848600387573, 1.5719258785247803]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.873727560043335, 0.4226757884025574, 0.25770556926727295, 0.8666207790374756, -1.3351552486419678]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 11 Average Loss: 2.4485\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8535568118095398, 0.35527390241622925, 0.3853974938392639, 0.8662794828414917, -1.291191816329956]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep12 Batch0/19, Loss=2.4472\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8734749555587769, 0.4432674050331116, 0.23805396258831024, 0.7921865582466125, -1.269473910331726]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7914857864379883, 0.40870559215545654, 0.2842209041118622, 0.7534979581832886, -1.3026522397994995]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8651134967803955, 0.42853379249572754, 0.3019155263900757, 0.8878207802772522, -1.2868188619613647]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8353165984153748, 0.3444865643978119, 0.3391534984111786, 0.8542203903198242, -1.2932888269424438]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8107602596282959, 0.4104812741279602, 0.2806626856327057, 0.8175723552703857, -1.3780059814453125]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.076639175415039, -0.030723437666893005, -0.6501466631889343, -1.1162711381912231, 1.6355907917022705]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8183647394180298, 0.3972928524017334, 0.32878002524375916, 0.7985907196998596, -1.31308114528656]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8713271021842957, 0.44995465874671936, 0.3532679080963135, 0.8446769714355469, -1.2757489681243896]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8840980529785156, 0.42201194167137146, 0.4001722037792206, 0.889295220375061, -1.283873438835144]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.046764373779297, -0.041737038642168045, -0.7607223987579346, -1.1354864835739136, 1.5653765201568604]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep12 Batch10/19, Loss=2.4451\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.9166486263275146, 0.4188630282878876, 0.400729238986969, 0.8388737440109253, -1.3125531673431396]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8568156957626343, 0.4336507320404053, 0.30322563648223877, 0.8474329710006714, -1.2911396026611328]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.030489206314087, -0.021061928942799568, -0.6337645649909973, -1.2387720346450806, 1.570334553718567]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0072484016418457, -0.051797203719615936, -0.6165298223495483, -1.1231200695037842, 1.5809727907180786]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8782158493995667, 0.3912806510925293, 0.26515117287635803, 0.9059377908706665, -1.3201313018798828]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0235514640808105, 0.003252762835472822, -0.7192450761795044, -1.1225666999816895, 1.5817829370498657]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8313558101654053, 0.44340023398399353, 0.2443467080593109, 0.9001905918121338, -1.3227283954620361]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.7750914692878723, 0.4825190007686615, 0.2504117786884308, 0.7992899417877197, -1.2737293243408203]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 12 Average Loss: 2.4437\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8061143755912781, 0.43865808844566345, 0.31425437331199646, 0.8130384087562561, -1.3613698482513428]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep13 Batch0/19, Loss=2.4103\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8589494824409485, 0.3445390462875366, 0.2943947911262512, 0.8163295388221741, -1.264161467552185]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.834483802318573, 0.46507754921913147, 0.3328121602535248, 0.7637090086936951, -1.3083481788635254]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8543498516082764, 0.42712637782096863, 0.19221650063991547, 0.8796228766441345, -1.3061355352401733]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8290703296661377, 0.42182013392448425, 0.33096352219581604, 0.8308230042457581, -1.2138760089874268]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7866697311401367, 0.4538476765155792, 0.3231276869773865, 0.7145017981529236, -1.291912317276001]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8483909368515015, 0.38416022062301636, 0.298694908618927, 0.7509589195251465, -1.2906078100204468]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0310964584350586, -0.032656457275152206, -0.650672972202301, -1.068652629852295, 1.5401231050491333]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9475938081741333, -0.062138888984918594, -0.7119778394699097, -1.1663146018981934, 1.5777629613876343]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8424202799797058, 0.447461873292923, 0.3915824592113495, 0.9213915467262268, -1.2788418531417847]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7741323113441467, 0.47002777457237244, 0.3105039596557617, 0.8121691942214966, -1.2265502214431763]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep13 Batch10/19, Loss=2.4456\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9481412172317505, -0.01861763373017311, -0.6951450109481812, -1.1333887577056885, 1.5699591636657715]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8167461156845093, 0.39364585280418396, 0.2620382308959961, 0.840046226978302, -1.228208065032959]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9723683595657349, 0.003927126992493868, -0.6523764729499817, -1.0380860567092896, 1.561776876449585]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7306404113769531, 0.3676677346229553, 0.3154991567134857, 0.8849471807479858, -1.2843661308288574]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8331335186958313, 0.4773552417755127, 0.22376278042793274, 0.8213040828704834, -1.3226282596588135]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.742032527923584, 0.3811340928077698, 0.36426958441734314, 0.7878274321556091, -1.2382595539093018]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9974220991134644, -0.03204626962542534, -0.7208078503608704, -1.121164083480835, 1.5614405870437622]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.7922576069831848, 0.41806474328041077, 0.3048233091831207, 0.7924370169639587, -1.260678768157959]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 13 Average Loss: 2.4438\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.804050624370575, 0.46668076515197754, 0.31989508867263794, 0.8303195238113403, -1.2374296188354492]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep14 Batch0/19, Loss=2.4513\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.06857967376709, -0.09874903410673141, -0.7232329845428467, -1.082367181777954, 1.4927319288253784]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8155274391174316, 0.41900768876075745, 0.29632335901260376, 0.8322420120239258, -1.2466964721679688]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.724507212638855, 0.4779032766819, 0.29518067836761475, 0.8127079010009766, -1.2832828760147095]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8672710061073303, 0.41063278913497925, 0.2161245346069336, 0.8355516791343689, -1.1987375020980835]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.8110795021057129, 0.43147972226142883, 0.34509798884391785, 0.8562420010566711, -1.2699823379516602]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7453540563583374, 0.41149646043777466, 0.2765130400657654, 0.7675288915634155, -1.3020492792129517]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7588750720024109, 0.5165802240371704, 0.34742340445518494, 0.7151698470115662, -1.259112000465393]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9724695682525635, 0.04447298124432564, -0.6639440655708313, -1.131746768951416, 1.5107172727584839]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0319812297821045, -0.012079378589987755, -0.6545840501785278, -1.0830413103103638, 1.5064715147018433]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0724611282348633, -0.05396449938416481, -0.7190299034118652, -1.048930048942566, 1.661757469177246]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep14 Batch10/19, Loss=2.4187\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0482635498046875, -0.046300359070301056, -0.7347137928009033, -1.147419810295105, 1.5274337530136108]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7294981479644775, 0.4024626910686493, 0.27334076166152954, 0.8118581175804138, -1.2409449815750122]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7311922311782837, 0.47025221586227417, 0.3368167579174042, 0.7329095005989075, -1.2173092365264893]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7790595293045044, 0.426798015832901, 0.23282070457935333, 0.7291467785835266, -1.1914379596710205]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0946462154388428, -0.019184095785021782, -0.6964918375015259, -1.1500555276870728, 1.5206835269927979]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7853052616119385, 0.44419601559638977, 0.35255393385887146, 0.7821145057678223, -1.2083773612976074]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.040142774581909, 0.029340706765651703, -0.7347878217697144, -1.0757757425308228, 1.596893310546875]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-2.05527663230896, 0.00238889385946095, -0.7091323137283325, -1.0861055850982666, 1.58378005027771]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 14 Average Loss: 2.4423\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0102384090423584, -0.014405881054699421, -0.7820044159889221, -1.1327054500579834, 1.5236847400665283]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep15 Batch0/19, Loss=2.4424\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6944562792778015, 0.4219192862510681, 0.2060765027999878, 0.6961745619773865, -1.2724336385726929]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.764802873134613, 0.40090715885162354, 0.24238209426403046, 0.6509494185447693, -1.258420705795288]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7818284034729004, 0.3932535946369171, 0.32663145661354065, 0.7132094502449036, -1.2158372402191162]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9999686479568481, -0.06770142167806625, -0.7448195219039917, -1.0994598865509033, 1.554173469543457]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7323263883590698, 0.46927493810653687, 0.2217404544353485, 0.81332927942276, -1.2592720985412598]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6683241128921509, 0.43318042159080505, 0.4167737364768982, 0.7655962109565735, -1.1834057569503784]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6793047785758972, 0.45230621099472046, 0.3401380479335785, 0.6663645505905151, -1.2703073024749756]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.692371129989624, 0.446910560131073, 0.22543485462665558, 0.7265764474868774, -1.2720292806625366]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6883512735366821, 0.45077815651893616, 0.2948457598686218, 0.7026659846305847, -1.2451884746551514]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7582532167434692, 0.413604199886322, 0.2825285494327545, 0.7556034922599792, -1.2240557670593262]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep15 Batch10/19, Loss=2.4382\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7349647283554077, 0.43195465207099915, 0.29274120926856995, 0.613297700881958, -1.2322044372558594]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7311995625495911, 0.4702453017234802, 0.3218974173069, 0.7424620389938354, -1.2678347826004028]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6441006064414978, 0.4803714454174042, 0.3249327540397644, 0.6792593598365784, -1.238856554031372]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7163219451904297, 0.4462759494781494, 0.304855614900589, 0.7456361055374146, -1.1721440553665161]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7145229578018188, 0.41735026240348816, 0.25255030393600464, 0.7164921760559082, -1.2925547361373901]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7212555408477783, 0.4399513006210327, 0.230198934674263, 0.6992312669754028, -1.1962804794311523]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0901503562927246, -0.01170708891004324, -0.7999181747436523, -1.1075000762939453, 1.554154396057129]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.6519864797592163, 0.4201657176017761, 0.3003709316253662, 0.7381585836410522, -1.1964218616485596]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 15 Average Loss: 2.4436\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.017751693725586, -0.004341399762779474, -0.7650564908981323, -1.1622449159622192, 1.532249927520752]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep16 Batch0/19, Loss=2.4563\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.719787061214447, 0.4167460501194, 0.25502002239227295, 0.7029580473899841, -1.202731728553772]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7646120190620422, 0.37920916080474854, 0.36413344740867615, 0.6542450189590454, -1.21518075466156]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6858358383178711, 0.40239349007606506, 0.2296796441078186, 0.8010187149047852, -1.2179042100906372]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6927047371864319, 0.44071072340011597, 0.31590259075164795, 0.602378249168396, -1.140904426574707]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0679309368133545, 0.09137140959501266, -0.8284733295440674, -1.0953803062438965, 1.5660762786865234]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7183768153190613, 0.43599653244018555, 0.31633952260017395, 0.7171185612678528, -1.128857970237732]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7095838785171509, 0.39249488711357117, 0.2425234019756317, 0.7855031490325928, -1.2842464447021484]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6927711963653564, 0.4997358024120331, 0.3209960162639618, 0.7113151550292969, -1.2026206254959106]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0095412731170654, -0.02720579318702221, -0.7449559569358826, -1.0767077207565308, 1.5512912273406982]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6953736543655396, 0.42112070322036743, 0.22966772317886353, 0.5813031792640686, -1.1862009763717651]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep16 Batch10/19, Loss=2.4450\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.667512834072113, 0.4403190016746521, 0.28099945187568665, 0.6685798168182373, -1.2137032747268677]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6761003136634827, 0.4608708918094635, 0.2885626554489136, 0.6295099854469299, -1.23497474193573]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7067172527313232, 0.42928338050842285, 0.3428954780101776, 0.6658118367195129, -1.1629797220230103]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0406570434570312, -0.0038135391660034657, -0.7207105755805969, -1.0859096050262451, 1.5037429332733154]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5835137963294983, 0.40867123007774353, 0.3257656395435333, 0.6869760751724243, -1.1599832773208618]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6233700513839722, 0.4054729640483856, 0.2537158727645874, 0.7038176655769348, -1.2648597955703735]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6599270105361938, 0.41006964445114136, 0.2274860292673111, 0.6874467134475708, -1.2291901111602783]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-2.027139902114868, -0.0019477196037769318, -0.6978961229324341, -1.1484999656677246, 1.489004373550415]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 16 Average Loss: 2.4422\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6230115294456482, 0.40622764825820923, 0.19767719507217407, 0.7246968150138855, -1.1633726358413696]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep17 Batch0/19, Loss=2.4435\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0431809425354004, 0.04765811935067177, -0.7368277907371521, -1.0257362127304077, 1.5515695810317993]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.047182083129883, -0.000890562660060823, -0.7596925497055054, -1.076586127281189, 1.4744229316711426]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.617876410484314, 0.4271567761898041, 0.282417356967926, 0.619174599647522, -1.1515350341796875]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0754928588867188, -0.024185629561543465, -0.6840463876724243, -1.0275070667266846, 1.48993718624115]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5821309089660645, 0.4992600679397583, 0.26588907837867737, 0.61199951171875, -1.2255369424819946]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.086442470550537, -0.06545384228229523, -0.7533155679702759, -1.1398333311080933, 1.5657438039779663]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6043910980224609, 0.48091545701026917, 0.28943151235580444, 0.6628040671348572, -1.1749917268753052]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0448381900787354, -0.0368943065404892, -0.6907988786697388, -1.0578192472457886, 1.5419222116470337]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5641217827796936, 0.40863364934921265, 0.2874195873737335, 0.6250332593917847, -1.1846948862075806]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.7066164612770081, 0.3735974431037903, 0.15308408439159393, 0.6078159809112549, -1.1580371856689453]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep17 Batch10/19, Loss=2.4444\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6382629871368408, 0.4639304578304291, 0.22221417725086212, 0.6696897745132446, -1.2148051261901855]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6028105020523071, 0.34493550658226013, 0.2819423973560333, 0.6701614260673523, -1.154287338256836]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6276277899742126, 0.4840630292892456, 0.3026631772518158, 0.6521283984184265, -1.248616099357605]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6615698933601379, 0.41497355699539185, 0.21604931354522705, 0.6692764759063721, -1.2397828102111816]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6696975231170654, 0.4669373631477356, 0.24872171878814697, 0.6566798686981201, -1.1526025533676147]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6179222464561462, 0.42937010526657104, 0.26419001817703247, 0.6369069814682007, -1.200992465019226]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.966697335243225, -0.012006186880171299, -0.754460871219635, -1.0842030048370361, 1.5629427433013916]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.5032413005828857, 0.3894105553627014, 0.21649517118930817, 0.6115177869796753, -1.1943011283874512]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 17 Average Loss: 2.4429\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5457586050033569, 0.4246194064617157, 0.2745950222015381, 0.5214948654174805, -1.1734929084777832]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep18 Batch0/19, Loss=2.4658\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5470550060272217, 0.3557920753955841, 0.19032515585422516, 0.6005409359931946, -1.2092819213867188]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9776368141174316, -0.009138998575508595, -0.6776695847511292, -1.0724093914031982, 1.568671703338623]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.082692861557007, 0.03978801518678665, -0.7045618891716003, -1.074245810508728, 1.5170255899429321]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5524020195007324, 0.41611623764038086, 0.33581843972206116, 0.5156172513961792, -1.075265645980835]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.036078929901123, -0.027979496866464615, -0.7048349380493164, -1.1379681825637817, 1.5060518980026245]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6806813478469849, 0.3959748148918152, 0.29834112524986267, 0.6608110070228577, -1.1117910146713257]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5691078305244446, 0.4212920665740967, 0.23967264592647552, 0.6349210143089294, -1.122822880744934]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.072929620742798, -0.06377533078193665, -0.6667692065238953, -1.1327309608459473, 1.4516992568969727]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.030959129333496, 0.04990256205201149, -0.6765310168266296, -1.0610734224319458, 1.5969886779785156]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.6313635110855103, 0.45159822702407837, 0.2553612291812897, 0.6302450895309448, -1.167410969734192]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep18 Batch10/19, Loss=2.4285\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.591111958026886, 0.4082626402378082, 0.3377346098423004, 0.6546023488044739, -1.1250150203704834]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4746038019657135, 0.4154644012451172, 0.285127729177475, 0.6284264326095581, -1.1250253915786743]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5326390266418457, 0.4002404808998108, 0.2766549587249756, 0.5083032250404358, -1.1522136926651]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4534009099006653, 0.4291532337665558, 0.27235734462738037, 0.5361477136611938, -1.1643491983413696]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5425100326538086, 0.40600770711898804, 0.22031860053539276, 0.5976353287696838, -1.121813416481018]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0668067932128906, 0.006389448419213295, -0.6653777956962585, -1.064835548400879, 1.4503679275512695]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5127753615379333, 0.39030417799949646, 0.25109219551086426, 0.529556155204773, -1.1938917636871338]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-2.087416887283325, -0.005164166446775198, -0.6940606236457825, -1.0734212398529053, 1.5764458179473877]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 18 Average Loss: 2.4394\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9627631902694702, 0.0034320405684411526, -0.7033669948577881, -1.1196322441101074, 1.609101414680481]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep19 Batch0/19, Loss=2.4475\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.48464590311050415, 0.4633367359638214, 0.11603769659996033, 0.5895135998725891, -1.1658624410629272]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.45744454860687256, 0.42988792061805725, 0.21979519724845886, 0.5257893800735474, -1.1596773862838745]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.976389765739441, 0.01782773807644844, -0.7208058834075928, -1.0460565090179443, 1.5910547971725464]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5953240990638733, 0.5331223607063293, 0.3038010597229004, 0.5781787633895874, -1.1666103601455688]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5519510507583618, 0.4673961400985718, 0.27910715341567993, 0.631614625453949, -1.1274409294128418]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5668060779571533, 0.4008524417877197, 0.11050845682621002, 0.6269391179084778, -1.127977728843689]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.480782687664032, 0.4900321364402771, 0.17120882868766785, 0.5331006050109863, -1.121282935142517]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0615646839141846, 0.027801865711808205, -0.7210108637809753, -1.0323013067245483, 1.5364902019500732]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4409051537513733, 0.3481898903846741, 0.2745048403739929, 0.5482076406478882, -1.150773525238037]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4453839957714081, 0.3771190047264099, 0.17485478520393372, 0.6625627279281616, -1.1041252613067627]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep19 Batch10/19, Loss=2.4605\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4275125563144684, 0.4274599850177765, 0.19305264949798584, 0.5019657015800476, -1.1627596616744995]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9849165678024292, 0.0032606408931314945, -0.7271348834037781, -1.0184170007705688, 1.5488755702972412]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0050225257873535, -0.012889225035905838, -0.6976768374443054, -1.074647307395935, 1.5588550567626953]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4515003561973572, 0.42379483580589294, 0.22127312421798706, 0.5072231888771057, -1.1691747903823853]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.025479555130005, -0.013222401030361652, -0.6766991019248962, -1.0815742015838623, 1.6254549026489258]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.5195611715316772, 0.4288395643234253, 0.22296202182769775, 0.6057212352752686, -1.0913687944412231]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4611266851425171, 0.4508865773677826, 0.17786096036434174, 0.5774643421173096, -1.0796056985855103]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[0.46103599667549133, 0.3753536343574524, 0.1822529286146164, 0.49577295780181885, -1.114275574684143]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 19 Average Loss: 2.4411\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9612830877304077, 0.044458601623773575, -0.6012176871299744, -1.1148836612701416, 1.5859884023666382]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep20 Batch0/19, Loss=2.4223\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4246932864189148, 0.389342337846756, 0.2503640949726105, 0.49931153655052185, -1.0875564813613892]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0080671310424805, -0.011748701333999634, -0.7538958191871643, -1.1084527969360352, 1.4970372915267944]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4443458020687103, 0.47377675771713257, 0.24427340924739838, 0.4534235894680023, -1.1401346921920776]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3701384365558624, 0.4024193286895752, 0.30253466963768005, 0.4334448277950287, -1.0198034048080444]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.024670124053955, -0.06309732794761658, -0.7240278720855713, -1.0908952951431274, 1.5360448360443115]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.02496337890625, 0.009555731900036335, -0.7089041471481323, -1.1250649690628052, 1.549091100692749]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4438619911670685, 0.4087546169757843, 0.16493257880210876, 0.5042065978050232, -1.0609495639801025]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9710907936096191, -0.001928412588313222, -0.7071018218994141, -1.1135329008102417, 1.5287553071975708]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-1.9815640449523926, 0.0793147161602974, -0.749406635761261, -1.041063666343689, 1.628134846687317]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.43589580059051514, 0.48328888416290283, 0.22312574088573456, 0.5070632100105286, -1.1193361282348633]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Train] Ep20 Batch10/19, Loss=2.4405\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.113858938217163, 0.04276809096336365, -0.8011165857315063, -1.052008867263794, 1.520724892616272]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3796720802783966, 0.4868658185005188, 0.236142098903656, 0.5245441198348999, -1.1140391826629639]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.4050070345401764, 0.4183569848537445, 0.29516035318374634, 0.5158593654632568, -1.1037096977233887]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.0551230907440186, -0.031880345195531845, -0.7275460958480835, -1.1190940141677856, 1.59596848487854]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.061614990234375, -0.02973705716431141, -0.7114460468292236, -1.1090916395187378, 1.5591720342636108]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[-2.072751998901367, 0.07328096777200699, -0.828280508518219, -1.0528348684310913, 1.6024435758590698]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([32, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([32, 512]), sample h[0][:5]=[0.3537331521511078, 0.4246123731136322, 0.16181334853172302, 0.5528494715690613, -1.0794161558151245]\n",
      "[Decoder] logits shape: torch.Size([32, 16, 128])\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='HELLO CUBIST' -> ids=[72, 69, 76, 76, 79, 32, 67, 85, 66, 73, 83, 84, 0, 0, 0, 0]\n",
      "[Tokenizer] text='NOISE DECOY' -> ids=[78, 79, 73, 83, 69, 32, 68, 69, 67, 79, 89, 0, 0, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Tokenizer] text='AI ENCRYPTION' -> ids=[65, 73, 32, 69, 78, 67, 82, 89, 80, 84, 73, 79, 78, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([24, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([24, 512]), sample h[0][:5]=[-2.045881986618042, 0.13447079062461853, -0.7598574161529541, -1.0681133270263672, 1.476691484451294]\n",
      "[Decoder] logits shape: torch.Size([24, 16, 128])\n",
      "[Train] Epoch 20 Average Loss: 2.4451\n",
      "[Inference] test_text='SECURE TEST'\n",
      "[Tokenizer] text='SECURE TEST' -> ids=[83, 69, 67, 85, 82, 69, 32, 84, 69, 83, 84, 0, 0, 0, 0, 0]\n",
      "[Encoder] embed output shape: torch.Size([1, 16, 256])\n",
      "[Encoder] latent h shape: torch.Size([1, 512]), sample h[0][:5]=[0.415311336517334, 0.35401925444602966, 0.2298816591501236, 0.5051403641700745, -1.0723627805709839]\n",
      "[Obfuscate] noise mean=0.0405, std=1.4833\n",
      "[Stylizer] generated image batch shape: torch.Size([1, 3, 64, 64])\n",
      "[Inference] Encrypted image saved: cipher_final.png\n",
      "[Decoder] logits shape: torch.Size([1, 11, 128])\n",
      "[Inference] Decrypted after training: 'IINOINNEIIN'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# 고정 시드\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# --- Simple Tokenizer ---\n",
    "def simple_tokenize(text, vocab_size=128, max_len=16):\n",
    "    ids = [ord(c) % vocab_size for c in text][:max_len]\n",
    "    ids += [0] * (max_len - len(ids))\n",
    "    print(f\"[Tokenizer] text='{text}' -> ids={ids}\")\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "# --- Encoder: Text Batch -> Latent Batch ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size=128, embed_dim=256, latent_dim=512, n_layers=4, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "        self.to_latent = nn.Linear(embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids: [batch, seq_len]\n",
    "        x = self.embed(input_ids)                # [batch, seq_len, embed_dim]\n",
    "        print(f\"[Encoder] embed output shape: {x.shape}\")\n",
    "        x = x.permute(1, 0, 2)                    # [seq_len, batch, embed_dim]\n",
    "        x = self.transformer(x)                  # [seq_len, batch, embed_dim]\n",
    "        h_feat = x.mean(dim=0)                   # [batch, embed_dim]\n",
    "        h = self.to_latent(h_feat)               # [batch, latent_dim]\n",
    "        print(f\"[Encoder] latent h shape: {h.shape}, sample h[0][:5]={h[0,:5].tolist()}\")\n",
    "        return h\n",
    "\n",
    "# --- Noise & Decoy ---\n",
    "def obfuscate(h, sigma=1.0, decoy_dim=0):\n",
    "    noise = torch.randn_like(h) * sigma\n",
    "    h_noisy = h + noise\n",
    "    print(f\"[Obfuscate] noise mean={noise.mean().item():.4f}, std={noise.std().item():.4f}\")\n",
    "    if decoy_dim > 0:\n",
    "        batch = h_noisy.size(0)\n",
    "        d = torch.randn(batch, decoy_dim)\n",
    "        h_mix = torch.cat([h_noisy, d], dim=1)\n",
    "        print(f\"[Obfuscate] added decoy of dim {decoy_dim}, h_mix shape: {h_mix.shape}\")\n",
    "        return h_mix\n",
    "    return h_noisy\n",
    "\n",
    "# --- Stylizer: Latent Batch -> Image Batch ---\n",
    "class Stylizer(nn.Module):\n",
    "    def __init__(self, latent_dim=512, img_size=64):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 3 * img_size * img_size)\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def forward(self, h):\n",
    "        img_flat = self.fc(h)                    # [batch, 3*H*W]\n",
    "        b, _ = img_flat.shape\n",
    "        img = img_flat.view(b, 3, self.img_size, self.img_size)\n",
    "        img = torch.sigmoid(img)\n",
    "        print(f\"[Stylizer] generated image batch shape: {img.shape}\")\n",
    "        return img\n",
    "\n",
    "# --- Decoder: Latent Batch -> Logits Batch ---\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=512, embed_dim=256, vocab_size=128, n_layers=4, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, embed_dim)\n",
    "        layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.transformer = nn.TransformerDecoder(layer, num_layers=n_layers)\n",
    "        self.to_logits = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, h, seq_len):\n",
    "        b = h.size(0)\n",
    "        memory = self.fc(h).unsqueeze(0)         # [1, batch, embed_dim]\n",
    "        tgt = torch.zeros(seq_len, b, memory.size(-1))\n",
    "        out = self.transformer(tgt, memory)      # [seq_len, batch, embed_dim]\n",
    "        out = out.permute(1, 0, 2)               # [batch, seq_len, embed_dim]\n",
    "        logits = self.to_logits(out)             # [batch, seq_len, vocab]\n",
    "        print(f\"[Decoder] logits shape: {logits.shape}\")\n",
    "        return logits\n",
    "\n",
    "# --- Dataset for Autoencoder Training ---\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, max_len=16):\n",
    "        self.texts = texts\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        ids = simple_tokenize(self.texts[idx], max_len=self.max_len)\n",
    "        return ids, ids\n",
    "\n",
    "# --- Main Training & Inference ---\n",
    "def main():\n",
    "    # Settings\n",
    "    vocab_size = 128\n",
    "    latent_dim = 512\n",
    "    seq_len = 16\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    sigma = 1.5\n",
    "\n",
    "    print(f\"[Config] vocab_size={vocab_size}, latent_dim={latent_dim}, seq_len={seq_len}, batch_size={batch_size}, epochs={epochs}, sigma={sigma}\")\n",
    "\n",
    "    # Data\n",
    "    texts = [\"HELLO CUBIST\", \"NOISE DECOY\", \"AI ENCRYPTION\"] * 200\n",
    "    dataset = TextDataset(texts, max_len=seq_len)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(f\"[Data] Loaded {len(dataset)} examples, {len(dataloader)} batches per epoch\")\n",
    "\n",
    "    # Model\n",
    "    encoder = Encoder(vocab_size=vocab_size, latent_dim=latent_dim)\n",
    "    stylizer = Stylizer(latent_dim=latent_dim, img_size=64)\n",
    "    decoder = Decoder(latent_dim=latent_dim, embed_dim=256, vocab_size=vocab_size)\n",
    "\n",
    "    # Optimizer & Loss\n",
    "    optim = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    # Training\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (inp, tgt) in enumerate(dataloader):\n",
    "            optim.zero_grad()\n",
    "            h = encoder(inp)\n",
    "            logits = decoder(h, seq_len)\n",
    "            loss = criterion(logits.view(-1, vocab_size), tgt.view(-1))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total_loss += loss.item()\n",
    "            if i % 10 == 0:\n",
    "                print(f\"[Train] Ep{ep+1} Batch{i}/{len(dataloader)}, Loss={loss.item():.4f}\")\n",
    "        print(f\"[Train] Epoch {ep+1} Average Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    # Inference\n",
    "    test_text = \"SECURE TEST\"\n",
    "    print(f\"[Inference] test_text='{test_text}'\")\n",
    "    ids = simple_tokenize(test_text, vocab_size=vocab_size, max_len=seq_len).unsqueeze(0)\n",
    "    h = encoder(ids)\n",
    "    h_mix = obfuscate(h, sigma=sigma, decoy_dim=0)\n",
    "    img = stylizer(h_mix)\n",
    "    save_image(img, 'cipher_final.png')\n",
    "    print(\"[Inference] Encrypted image saved: cipher_final.png\")\n",
    "\n",
    "    logits = decoder(h, seq_len=len(test_text))\n",
    "    pred = logits.argmax(-1)[0]\n",
    "    recovered = ''.join(chr(int(x) % 128) for x in pred)\n",
    "    print(f\"[Inference] Decrypted after training: '{recovered}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fec3388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.2519\n",
      "Epoch 2, Loss: 2.6721\n",
      "Epoch 3, Loss: 2.4578\n",
      "Epoch 4, Loss: 2.2895\n",
      "Epoch 5, Loss: 2.1112\n",
      "Epoch 6, Loss: 1.9121\n",
      "Epoch 7, Loss: 1.7144\n",
      "Epoch 8, Loss: 1.5108\n",
      "Epoch 9, Loss: 1.2942\n",
      "Epoch 10, Loss: 1.0680\n",
      "Decoded: HELLT  ORIDERRRRRRRRRRRRRRRRRRRR\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# --- Character-Level Tokenizer ---\n",
    "class CharTokenizer:\n",
    "    def __init__(self):\n",
    "        self.chars = [chr(i) for i in range(32, 127)]  # printable ASCII\n",
    "        self.stoi = {c:i for i,c in enumerate(self.chars, start=1)}\n",
    "        self.itos = {i:c for c,i in self.stoi.items()}\n",
    "        self.vocab_size = len(self.stoi) + 1  # +1 for pad\n",
    "    def encode(self, text, max_len=32):\n",
    "        ids = [self.stoi.get(c, 0) for c in text][:max_len]\n",
    "        ids += [0]*(max_len-len(ids))\n",
    "        return torch.tensor(ids, dtype=torch.long)\n",
    "    def decode(self, ids):\n",
    "        return ''.join(self.itos.get(i, '') for i in ids if i>0)\n",
    "\n",
    "# --- Simple Autoencoder ---\n",
    "class SimpleAE(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128, seq_len=32):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.encoder = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.seq_len = seq_len\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len]\n",
    "        emb = self.embed(x)\n",
    "        _, h = self.encoder(emb)\n",
    "        # Prepare decoder input: start tokens (zeros)\n",
    "        dec_in = torch.zeros_like(x)\n",
    "        emb_dec = self.embed(dec_in)\n",
    "        out, _ = self.decoder(emb_dec, h)\n",
    "        logits = self.out(out)  # [batch, seq_len, vocab]\n",
    "        return logits\n",
    "\n",
    "# --- Dataset ---\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, i):\n",
    "        ids = self.tok.encode(self.texts[i], self.max_len)\n",
    "        return ids, ids\n",
    "\n",
    "# --- Run Prototype ---\n",
    "def run_simple_ae():\n",
    "    # Prepare\n",
    "    tok = CharTokenizer()\n",
    "    texts = [\"HELLO WORLD\", \"TEST STRING\", \"CUBIST CIPHER\"] * 100\n",
    "    ds = TextDataset(texts, tok, max_len=32)\n",
    "    dl = DataLoader(ds, batch_size=16, shuffle=True)\n",
    "    model = SimpleAE(tok.vocab_size, seq_len=32)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    crit = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(10):\n",
    "        total=0\n",
    "        for inp, tgt in dl:\n",
    "            opt.zero_grad()\n",
    "            logits = model(inp)\n",
    "            loss = crit(logits.view(-1, tok.vocab_size), tgt.view(-1))\n",
    "            loss.backward(); opt.step()\n",
    "            total+=loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total/len(dl):.4f}\")\n",
    "\n",
    "    # Test\n",
    "    sample = \"HELLO CIPHER\"\n",
    "    ids = tok.encode(sample, 32).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(ids)\n",
    "        pred = logits.argmax(-1)[0]\n",
    "        print(\"Decoded:\", tok.decode(pred.tolist()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_simple_ae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e37c5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.5898\n",
      "Epoch 2/20, Loss: 4.5298\n",
      "Epoch 3/20, Loss: 4.4597\n",
      "Epoch 4/20, Loss: 4.3903\n",
      "Epoch 5/20, Loss: 4.2877\n",
      "Epoch 6/20, Loss: 4.1253\n",
      "Epoch 7/20, Loss: 3.8987\n",
      "Epoch 8/20, Loss: 3.5898\n",
      "Epoch 9/20, Loss: 3.3079\n",
      "Epoch 10/20, Loss: 3.1463\n",
      "Epoch 11/20, Loss: 3.0095\n",
      "Epoch 12/20, Loss: 3.0010\n",
      "Epoch 13/20, Loss: 2.8970\n",
      "Epoch 14/20, Loss: 2.8540\n",
      "Epoch 15/20, Loss: 2.8279\n",
      "Epoch 16/20, Loss: 2.8411\n",
      "Epoch 17/20, Loss: 2.8190\n",
      "Epoch 18/20, Loss: 2.8161\n",
      "Epoch 19/20, Loss: 2.7971\n",
      "Epoch 20/20, Loss: 2.7904\n",
      "Saved encrypted_images.png after training.\n",
      "Recovered[0]: AEEOCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Recovered[1]: AEEOCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Recovered[2]: AEEOCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Recovered[3]: AEEOCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Recovered[4]: AEEOCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Recovered[5]: AEEOCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# --- Char Tokenizer ---\n",
    "class CharTokenizer:\n",
    "    def __init__(self, max_len=32):\n",
    "        self.chars = [chr(i) for i in range(32, 127)]\n",
    "        self.stoi = {c: i for i, c in enumerate(self.chars, start=1)}  # pad=0\n",
    "        self.itos = {i: c for c, i in self.stoi.items()}\n",
    "        self.vocab_size = len(self.stoi) + 1\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def encode(self, text):\n",
    "        ids = [self.stoi.get(c, 0) for c in text][: self.max_len]\n",
    "        ids += [0] * (self.max_len - len(ids))\n",
    "        return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "    def decode(self, ids):\n",
    "        return ''.join(self.itos.get(int(i), '') for i in ids).strip()\n",
    "\n",
    "# --- Dummy Dataset ---\n",
    "class TextImageDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = [tokenizer.encode(t) for t in texts]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# --- Models ---\n",
    "class NoiseInjector(nn.Module):\n",
    "    def __init__(self, noise_level=0.1):\n",
    "        super().__init__()\n",
    "        self.noise_level = noise_level\n",
    "    def forward(self, x):\n",
    "        return x + torch.randn_like(x) * self.noise_level if self.training else x\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb=64, hid=128, lat=256):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb, padding_idx=0)\n",
    "        self.noise = NoiseInjector(0.2)\n",
    "        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n",
    "        self.fc = nn.Linear(hid, lat)\n",
    "    def forward(self, x):\n",
    "        e = self.noise(self.embed(x))\n",
    "        _, (h,_) = self.lstm(e)\n",
    "        return self.fc(h[-1])\n",
    "\n",
    "class AbstractionGenerator(nn.Module):\n",
    "    def __init__(self, lat=256, ch=3):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(lat, 128*8*8)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,64,4,2,1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, ch,4,2,1), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        f = self.fc(z).view(-1,128,8,8)\n",
    "        return self.deconv(f), f\n",
    "\n",
    "class DecryptionModel(nn.Module):\n",
    "    def __init__(self, ch=3, hid_feat=(128,8,8), lat=256, hid=128, vocab=100):\n",
    "        super().__init__()\n",
    "        c,h,w = hid_feat\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch,64,4,2,1), nn.ReLU(True),\n",
    "            nn.Conv2d(64,128,4,2,1), nn.ReLU(True)\n",
    "        )\n",
    "        self.fc_img = nn.Linear(128*h*w, lat)\n",
    "        self.fc_hid = nn.Linear(128*h*w, lat)\n",
    "        self.fc_comb = nn.Linear(lat*2, hid)\n",
    "        self.lstm = nn.LSTM(hid, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab)\n",
    "    def forward(self, img, hid, tgt_len):\n",
    "        img_z = self.fc_img(self.conv(img).view(img.size(0),-1))\n",
    "        hid_z = self.fc_hid(hid.view(hid.size(0),-1))\n",
    "        comb = torch.tanh(self.fc_comb(torch.cat([img_z, hid_z],1)))\n",
    "        init = comb.unsqueeze(0)\n",
    "        inp = torch.zeros(img.size(0), tgt_len, comb.size(-1), device=img.device)\n",
    "        o,_ = self.lstm(inp,(init,init))\n",
    "        return self.out(o)\n",
    "\n",
    "# --- Training Pipeline ---\n",
    "def train_autoencoder(texts, epochs=20, bs=4, lr=1e-3):\n",
    "    tok = CharTokenizer(max_len=32)\n",
    "    ds = TextImageDataset(texts, tok)\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "    enc = TextEncoder(tok.vocab_size)\n",
    "    gen = AbstractionGenerator(lat=256, ch=3)\n",
    "    dec = DecryptionModel(ch=3, hid_feat=(128,8,8), lat=256, hid=128, vocab=tok.vocab_size)\n",
    "\n",
    "    opt = torch.optim.Adam(list(enc.parameters())+list(gen.parameters())+list(dec.parameters()), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    enc.train(); gen.train(); dec.train()\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dl:\n",
    "            opt.zero_grad()\n",
    "            img, hid = gen(enc(batch))\n",
    "            logits = dec(img, hid, tok.max_len)\n",
    "            loss = criterion(logits.view(-1, tok.vocab_size), batch.view(-1))\n",
    "            loss.backward(); opt.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {ep+1}/{epochs}, Loss: {total_loss/len(dl):.4f}\")\n",
    "\n",
    "    return tok, enc, gen, dec\n",
    "\n",
    "if __name__=='__main__':\n",
    "    texts = [\n",
    "        'HELLO WORLD', 'PICASSO CRYPTO', 'ABSTRACT CODE', 'DEEP LEARNING',\n",
    "        'TORCH PYTHON', 'AUTOMATED ENCODING'\n",
    "    ]\n",
    "    tok, enc, gen, dec = train_autoencoder(texts)\n",
    "\n",
    "    # Test\n",
    "    enc.eval(); gen.eval(); dec.eval()\n",
    "    batch = torch.stack([tok.encode(t) for t in texts])\n",
    "    imgs, hid = gen(enc(batch))\n",
    "    save_image(imgs, 'encrypted_images.png', normalize=True)\n",
    "    print(\"Saved encrypted_images.png after training.\")\n",
    "    with torch.no_grad():\n",
    "        out = dec(imgs, hid, tok.max_len)\n",
    "    for i,ids in enumerate(out.argmax(-1)):\n",
    "        print(f\"Recovered[{i}]:\", tok.decode(ids))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
