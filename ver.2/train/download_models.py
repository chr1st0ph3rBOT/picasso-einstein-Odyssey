# download_models.py
from transformers import BertTokenizer, BertModel, BertLMHeadModel

# ν”„λ΅μ νΈμ—μ„ μ‚¬μ©ν•λ” λ¨λΈμ μ΄λ¦„
MODEL_NAME = 'bert-base-uncased'

def download_and_cache_model():
    """
    Hugging Face Hubμ—μ„ λ¨λΈ νμΌμ„ λ‹¤μ΄λ΅λ“ν•μ—¬ λ΅μ»¬ μ»΄ν“¨ν„°μ— μΊμ‹ν•©λ‹λ‹¤.
    """
    print(f"'{MODEL_NAME}' λ¨λΈ λ‹¤μ΄λ΅λ“λ¥Ό μ‹μ‘ν•©λ‹λ‹¤...")
    print("μΈν„°λ„· μ—°κ²°μ΄ ν•„μ”ν•λ©°, μ²μμ—λ” μ‹κ°„μ΄ λ‹¤μ† κ±Έλ¦΄ μ μμµλ‹λ‹¤.")
    
    try:
        # 1. ν† ν¬λ‚μ΄μ € λ‹¤μ΄λ΅λ“
        print("ν† ν¬λ‚μ΄μ € λ‹¤μ΄λ΅λ“ μ¤‘...")
        BertTokenizer.from_pretrained(MODEL_NAME)
        
        # 2. μΈμ½”λ”μ© λ¨λΈ λ‹¤μ΄λ΅λ“
        print("μΈμ½”λ” λ¨λΈ λ‹¤μ΄λ΅λ“ μ¤‘...")
        BertModel.from_pretrained(MODEL_NAME)
        
        # 3. λ””μ½”λ”μ© λ¨λΈ λ‹¤μ΄λ΅λ“
        print("λ””μ½”λ” λ¨λΈ λ‹¤μ΄λ΅λ“ μ¤‘...")
        BertLMHeadModel.from_pretrained(MODEL_NAME, is_decoder=True)
        
        print("\nπ‰ μ„±κ³µ: λ¨λ“  λ¨λΈ νμΌμ΄ μ„±κ³µμ μΌλ΅ λ‹¤μ΄λ΅λ“ λ° μΊμ‹λμ—μµλ‹λ‹¤.")
        print("μ΄μ  λ‹¤λ¥Έ μ•±λ“¤μ„ μΈν„°λ„· μ—°κ²° μ—†μ΄ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤.")

    except Exception as e:
        print(f"\nβ μ¤λ¥: λ¨λΈ λ‹¤μ΄λ΅λ“ μ¤‘ λ¬Έμ κ°€ λ°μƒν–μµλ‹λ‹¤.")
        print(f"μ—λ¬ λ©”μ‹μ§€: {e}")
        print("μΈν„°λ„· μ—°κ²° μƒνƒλ¥Ό ν™•μΈν•κ³  λ‹¤μ‹ μ‹λ„ν•΄ μ£Όμ„Έμ”.")

if __name__ == '__main__':
    download_and_cache_model()
